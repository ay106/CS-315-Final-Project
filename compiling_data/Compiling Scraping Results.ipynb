{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "786a048b-7ff3-430b-bc95-ac937dff1b3f",
   "metadata": {},
   "source": [
    "## Compiling Scraping Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97504d93-79af-4236-987f-abd235d6ec32",
   "metadata": {},
   "source": [
    "Author: Miraya\\\n",
    "Purpose: Creating csv files for pyktok scraped data that is correlated with year and search term data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc4d533c-84aa-4cdb-b96e-4ec9c4ac0554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "743619ee-e386-4218-9270-fb7e4fdac5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dict with search term and video ID as key and value\n",
    "def get_ID_search_term(json_dict):\n",
    "    result = {}\n",
    "    for key in json_dict:\n",
    "        # key is each search term\n",
    "        all_urls = json_dict[key]['urls']\n",
    "        for url in all_urls:\n",
    "            #get video ID\n",
    "            vid_ID = int(url[len(url)-19:])\n",
    "            result[vid_ID] = key\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45bfc53c-5f0f-4d94-b8ef-7268fb70e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vid_id(transcript_df):\n",
    "    all_ids = []\n",
    "    #transcript_df = pd.read_csv(filepath)\n",
    "    for index, row in transcript_df.iterrows():\n",
    "        transc_file_name = row['File Name']\n",
    "        tfl = len(transc_file_name)\n",
    "        transcript_id = int(transc_file_name[tfl-23:tfl-4])\n",
    "        all_ids.append(transcript_id)\n",
    "    transcript_df['video_id'] = all_ids\n",
    "    return transcript_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3a8ed98-13cd-48e3-9e02-92c2ae83533f",
   "metadata": {},
   "source": [
    "## Applying to all Result Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8fdef9b0-9a47-4b72-8103-9d89b92d7f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_csv():\n",
    "    #get list of files to compile\n",
    "    path = 'pyktok_csv_files'\n",
    "    all_files = os.listdir(path)\n",
    "    req_files = [file for file in all_files if 'failed' not in file]\n",
    "\n",
    "    #these files have all the terms for both chunks\n",
    "    json_path = 'json_result_files'\n",
    "    all_json_files = os.listdir(json_path)\n",
    "\n",
    "    transcript_path = 'transcript_csv_files'\n",
    "    all_transcript_files = os.listdir(transcript_path)\n",
    "\n",
    "    for f in req_files:\n",
    "        #opening csv results file and downloading as pandas \n",
    "       # fipa2 = f'{path}/{f}'\n",
    "      #  print(fipa2)\n",
    "        try:\n",
    "            df = pd.read_csv(os.path.join(path, f))\n",
    "        except: \n",
    "            print(os.path.join(path, f))\n",
    "        \n",
    "        year = f[7:11]\n",
    "        number = f[12:13]\n",
    "        for j in all_json_files:\n",
    "            if year in j:\n",
    "                print(j)\n",
    "                fipa = f'{json_path}/{j}'\n",
    "                with open (fipa, 'r') as json_file:\n",
    "                    data = json.load(json_file)\n",
    "                    search_term_dct = get_ID_search_term(data)\n",
    "\n",
    "                    search_term_column = []\n",
    "                    for index, row in df.iterrows():\n",
    "                        try:\n",
    "                            id = row['video_id']\n",
    "                            search_term_column.append(search_term_dct[id])\n",
    "                        except  Exception as e:\n",
    "                            print(f'{e}')\n",
    "                            search_term_column.append('')\n",
    "                        \n",
    "                    df['search_term'] = search_term_column\n",
    "                    df['year'] = [year] * df.shape[0]\n",
    "                    \n",
    "\n",
    "        for t in all_transcript_files:\n",
    "            year_transcript = t[11:15]\n",
    "            number_transcript = t[16:17]\n",
    "\n",
    "            if year == year_transcript and number == number_transcript:\n",
    "                transcript_df = add_vid_id(f'{transcript_path}/{t}')\n",
    "                #transcript_df\n",
    "                merged_df = pd.merge(df, transcript_df, on='video_id')\n",
    "\n",
    "                df.drop(columns=['video_id'])\n",
    "                \n",
    "                for col in transcript_df.columns:\n",
    "                    if col not in df.columns:\n",
    "                        df[col] = transcript_df[col]    \n",
    "            \n",
    "\n",
    "        df.to_csv(f'final_result_{year}_{number}.csv')\n",
    "        \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a98b4d7-ff6b-446e-bbe8-8b6c6f0f785f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv(year):\n",
    "    print (f'STARTING FOR YEAR {year}')\n",
    "    path = 'pyktok_csv_files'\n",
    "    all_files = os.listdir(path)\n",
    "    req_files = [file for file in all_files if 'failed' not in file]\n",
    "\n",
    "    pyktok_files = [filename for filename in req_files if year in filename]\n",
    "    \n",
    "    if len(pyktok_files) == 2:\n",
    "        pyktok_chunk1 = pd.read_csv(os.path.join(path, pyktok_files[0]))\n",
    "        pyktok_chunk2 = pd.read_csv(os.path.join(path, pyktok_files[1]))\n",
    "        pyktok_chunks = pd.concat([pyktok_chunk1, pyktok_chunk2])\n",
    "\n",
    "    else: \n",
    "        print(f'length of pyktok files is not 2')\n",
    "    print(f'there should be two files, the filenames are {pyktok_files} and the number of files is: {len(pyktok_files)}')\n",
    "\n",
    "    #these files have all the terms for both chunks\n",
    "    json_path = 'json_result_files'\n",
    "    all_json_files = os.listdir(json_path)\n",
    "    json_file = [j for j in all_json_files if year in j][0]\n",
    "    print('json file is' + json_file)\n",
    "\n",
    "    #create dict \n",
    "    with open (os.path.join(json_path, json_file), 'r') as jsonFile:\n",
    "        data = json.load(jsonFile)\n",
    "        search_term_dct = get_ID_search_term(data)\n",
    "\n",
    "    #transcript files read in\n",
    "    transcript_path = 'transcript_csv_files'\n",
    "    all_transcript_files = os.listdir(transcript_path)\n",
    "    transcript_files = [t for t in all_transcript_files if year in t]\n",
    "    print(f'no of transcript files found: {len(transcript_files)}')\n",
    "\n",
    "    if len(transcript_files) == 2:\n",
    "        t_chunk1 = pd.read_csv(os.path.join(transcript_path, transcript_files[0]))\n",
    "        t_chunk2 = pd.read_csv(os.path.join(transcript_path, transcript_files[1]))\n",
    "        t_chunks = pd.concat([t_chunk1, t_chunk2])\n",
    "\n",
    "    print(f'there should be two files, the filenames are {pyktok_files} and the number of files is: {len(pyktok_files)}')\n",
    "\n",
    "    #adding search term and year to pyktok df\n",
    "    print('adding search term and year to pyktok df')\n",
    "    search_term_column = []\n",
    "    for index, row in pyktok_chunks.iterrows():\n",
    "        try:\n",
    "            id = row['video_id']\n",
    "            search_term_column.append(search_term_dct[id])\n",
    "        except  Exception as e:\n",
    "            print(f'{e}')\n",
    "            print(f'could not find video id from json dict for video {row[\"video_id\"]}')\n",
    "            search_term_column.append(None)\n",
    "                        \n",
    "    pyktok_chunks['search_term'] = search_term_column\n",
    "    pyktok_chunks['year'] = [year] * pyktok_chunks.shape[0]\n",
    "\n",
    "    #add video id as column to transcript dfs \n",
    "    transcript_df = add_vid_id(t_chunks)\n",
    "\n",
    "    #merge the pyktok and t dfs\n",
    "\n",
    "    pyktok_chunks.merge(transcript_df, on='video_id', how='inner')\n",
    "    printI\n",
    "\n",
    "    #pyktok_chunks.drop(columns=['video_id'])\n",
    "    #for col in transcript_df.columns:\n",
    "    #    pyktok_chunks = pyktok_chunks.assign(new_column_name=transcript_df[column_name])\n",
    "        #pyktok_chunks[col] = transcript_df[col]    \n",
    "            \n",
    "\n",
    "    pyktok_chunks.to_csv(f'final_result_{year}.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbe99c2b-d9a0-49a8-9918-a8a3ea31ad8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING FOR YEAR 2020\n",
      "there should be two files, the filenames are ['results2020_2.csv', 'results2020_1.csv'] and the number of files is: 2\n",
      "json file isurls2020.json\n",
      "no of transcript files found: 2\n",
      "there should be two files, the filenames are ['results2020_2.csv', 'results2020_1.csv'] and the number of files is: 2\n",
      "adding search term and year to pyktok df\n"
     ]
    }
   ],
   "source": [
    "get_csv('2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a17ba47-cf86-426e-bd3b-9340d99be890",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
