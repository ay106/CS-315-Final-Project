{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aee19068-5adb-44eb-8f86-23a1e20673b2",
   "metadata": {},
   "source": [
    "## Modifying PykTok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2e49c5-34ba-4ce1-b372-ba6a8a5deb5c",
   "metadata": {},
   "source": [
    "PykTok code needs to be modified so the csv produced also stores year and search term information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e06e2cb0-bdcf-4829-9b05-15c955579ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pyktok as pyk\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32c8b234-9c21-419d-aeac-a7ea1ad924cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import browser_cookie3\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from csv import writer\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f18aac3-6e05-469d-955d-819bf66cd8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We strongly recommend you run 'specify_browser' first, which will allow you to run pyktok's functions without using the browser_name parameter every time. 'specify_browser' takes as its sole argument a string representing a browser installed on your system, e.g. \"chrome,\" \"firefox,\" \"edge,\" etc.\n"
     ]
    }
   ],
   "source": [
    "headers = {'Accept-Encoding': 'gzip, deflate, sdch',\n",
    "           'Accept-Language': 'en-US,en;q=0.8',\n",
    "           'Upgrade-Insecure-Requests': '1',\n",
    "           'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36',\n",
    "           'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "           'Cache-Control': 'max-age=0',\n",
    "           'Connection': 'keep-alive'}\n",
    "url_regex = '(?<=\\.com/)(.+?)(?=\\?|$)'\n",
    "runsb_rec = 'We strongly recommend you run \\'specify_browser\\' first, which will allow you to run pyktok\\'s functions without using the browser_name parameter every time. \\'specify_browser\\' takes as its sole argument a string representing a browser installed on your system, e.g. \"chrome,\" \"firefox,\" \"edge,\" etc.'\n",
    "runsb_err = 'No browser defined for cookie extraction. We strongly recommend you run \\'specify_browser\\', which takes as its sole argument a string representing a browser installed on your system, e.g. \"chrome,\" \"firefox,\" \"edge,\" etc.'\n",
    "\n",
    "print(runsb_rec)\n",
    "\n",
    "class BrowserNotSpecifiedError(Exception):\n",
    "    def __init__(self):\n",
    "        super().__init__(runsb_err)\n",
    "\n",
    "def specify_browser(browser):\n",
    "    print(\"YOU ARE RUNNING MODIFIED VER\")\n",
    "    global cookies\n",
    "    cookies = getattr(browser_cookie3,browser)(domain_name='www.tiktok.com')\n",
    "    \n",
    "def deduplicate_metadata(metadata_fn,video_df,dedup_field='video_id'):\n",
    "    if os.path.exists(metadata_fn):\n",
    "        metadata = pd.read_csv(metadata_fn,keep_default_na=False)\n",
    "        combined_data = pd.concat([metadata,video_df])\n",
    "        combined_data[dedup_field] = combined_data[dedup_field].astype(str)\n",
    "    else:\n",
    "        combined_data = video_df\n",
    "    return combined_data.drop_duplicates(dedup_field)\n",
    "\n",
    "def generate_data_row(video_obj):\n",
    "    data_header = ['video_id',\n",
    "                   'video_timestamp',\n",
    "                   'video_duration',\n",
    "                   'video_locationcreated',\n",
    "                   'suggested_words',\n",
    "                   'video_diggcount',\n",
    "                   'video_sharecount',\n",
    "                   'video_commentcount',\n",
    "                   'video_playcount',\n",
    "                   'video_description',\n",
    "                   'video_is_ad',\n",
    "                   'video_stickers',\n",
    "                   'author_username',\n",
    "                   'author_name',\n",
    "                   'author_followercount',\n",
    "                   'author_followingcount',\n",
    "                   'author_heartcount',\n",
    "                   'author_videocount',\n",
    "                   'author_diggcount',\n",
    "                   'author_verified']\n",
    "    data_list = []\n",
    "    data_list.append(video_obj['id'])\n",
    "    try:\n",
    "        ctime = video_obj['createTime']\n",
    "        data_list.append(datetime.fromtimestamp(int(ctime)).isoformat())\n",
    "    except Exception:\n",
    "        data_list.append('')\n",
    "    try:\n",
    "        data_list.append(video_obj['video']['duration'])\n",
    "    except Exception:\n",
    "        data_list.append(np.nan)\n",
    "    try:\n",
    "        data_list.append(video_obj['locationCreated'])\n",
    "    except Exception:\n",
    "        data_list.append('')\n",
    "    try:\n",
    "        data_list.append(\", \".join(video_obj['suggestedWords']))\n",
    "    except Exception:\n",
    "        data_list.append('')\n",
    "    try:\n",
    "        data_list.append(video_obj['stats']['diggCount'])\n",
    "    except Exception:\n",
    "        data_list.append(np.nan)\n",
    "    try:\n",
    "        data_list.append(video_obj['stats']['shareCount'])\n",
    "    except Exception:\n",
    "        data_list.append(np.nan)\n",
    "    try:\n",
    "        data_list.append(video_obj['stats']['commentCount'])\n",
    "    except Exception:\n",
    "        data_list.append(np.nan)\n",
    "    try:\n",
    "        data_list.append(video_obj['stats']['playCount'])\n",
    "    except Exception:\n",
    "        data_list.append(np.nan)\n",
    "    try:\n",
    "        data_list.append(video_obj['desc'])\n",
    "    except Exception:\n",
    "        data_list.append('')\n",
    "    try:\n",
    "        data_list.append(video_obj['isAd'])\n",
    "    except Exception:\n",
    "        data_list.append(False)\n",
    "    try:\n",
    "        video_stickers = []\n",
    "        for sticker in video_obj['stickersOnItem']:\n",
    "            for text in sticker['stickerText']:\n",
    "                video_stickers.append(text)\n",
    "        data_list.append(';'.join(video_stickers))\n",
    "    except Exception:\n",
    "        data_list.append('')\n",
    "    try:\n",
    "        data_list.append(video_obj['author']['uniqueId'])\n",
    "    except Exception:\n",
    "        try:\n",
    "            data_list.append(video_obj['author'])\n",
    "        except Exception:\n",
    "            data_list.append('')\n",
    "    try:\n",
    "        data_list.append(video_obj['author']['nickname'])\n",
    "    except Exception:\n",
    "        try:\n",
    "            data_list.append(video_obj['nickname'])\n",
    "        except Exception:\n",
    "            data_list.append('')\n",
    "    try:\n",
    "        data_list.append(video_obj['authorStats']['followerCount'])\n",
    "    except Exception:\n",
    "        data_list.append(np.nan)\n",
    "    try:\n",
    "        data_list.append(video_obj['authorStats']['followingCount'])\n",
    "    except Exception:\n",
    "        data_list.append(np.nan)\n",
    "    try:\n",
    "        data_list.append(video_obj['authorStats']['heartCount'])\n",
    "    except Exception:\n",
    "        data_list.append(np.nan)\n",
    "    try:\n",
    "        data_list.append(video_obj['authorStats']['videoCount'])\n",
    "    except Exception:\n",
    "        data_list.append(np.nan)\n",
    "    try:\n",
    "        data_list.append(video_obj['authorStats']['diggCount'])\n",
    "    except Exception:\n",
    "        data_list.append(np.nan)\n",
    "    try:\n",
    "        data_list.append(video_obj['author']['verified'])\n",
    "    except Exception:\n",
    "        data_list.append(False)\n",
    "    data_row = pd.DataFrame(dict(zip(data_header,data_list)),index=[0])\n",
    "    return data_row\n",
    "#currently unused, but leaving it in case it's needed later\n",
    "'''\n",
    "def fix_tt_url(tt_url):\n",
    "    if 'www.' not in tt_url.lower():\n",
    "        url_parts = tt_url.split('://')\n",
    "        fixed_url = url_parts[0] + '://www.' + url_parts[1]\n",
    "        return fixed_url\n",
    "    else:\n",
    "        return tt_url\n",
    "'''\n",
    "def get_tiktok_json(video_url,browser_name=None):\n",
    "    if 'cookies' not in globals() and browser_name is None:\n",
    "        raise BrowserNotSpecifiedError\n",
    "    global cookies\n",
    "    if browser_name is not None:\n",
    "        cookies = getattr(browser_cookie3,browser_name)(domain_name='www.tiktok.com')\n",
    "    try:\n",
    "        tt = requests.get(video_url,\n",
    "                        headers=headers,\n",
    "                        cookies=cookies,\n",
    "                        timeout=20)\n",
    "        # retain any new cookies that got set in this request\n",
    "        cookies = tt.cookies\n",
    "        soup = BeautifulSoup(tt.text, \"html.parser\")\n",
    "        tt_script = soup.find('script', attrs={'id':\"SIGI_STATE\"})\n",
    "        tt_json = json.loads(tt_script.string)\n",
    "    except:\n",
    "        return\n",
    "    return tt_json\n",
    "\n",
    "\n",
    "def alt_get_tiktok_json(video_url,browser_name=None):\n",
    "    if 'cookies' not in globals() and browser_name is None:\n",
    "        raise BrowserNotSpecifiedError\n",
    "    global cookies\n",
    "    if browser_name is not None:\n",
    "        cookies = getattr(browser_cookie3,browser_name)(domain_name='www.tiktok.com')\n",
    "    try:\n",
    "        tt = requests.get(video_url,\n",
    "                        headers=headers,\n",
    "                        cookies=cookies,\n",
    "                        timeout=20)\n",
    "        # retain any new cookies that got set in this request\n",
    "        cookies = tt.cookies\n",
    "        soup = BeautifulSoup(tt.text, \"html.parser\")\n",
    "        tt_script = soup.find('script', attrs={'id':\"__UNIVERSAL_DATA_FOR_REHYDRATION__\"})\n",
    "        tt_json = json.loads(tt_script.string)\n",
    "    except:\n",
    "        print(\"empty link, check failed_to_find.csv. Moving on..\")\n",
    "        return\n",
    "    return tt_json\n",
    "\n",
    "def save_tiktok(video_url,\n",
    "                save_video=True,\n",
    "                metadata_fn='',\n",
    "                browser_name=None):\n",
    "    if 'cookies' not in globals() and browser_name is None:\n",
    "        raise BrowserNotSpecifiedError\n",
    "    if save_video == False and metadata_fn == '':\n",
    "        print('Since save_video and metadata_fn are both False/blank, the program did nothing.')\n",
    "        return\n",
    "    \n",
    "    tt_video = None\n",
    "    tt_video_url = None\n",
    "    data_row = None\n",
    "    locate_el = True\n",
    "    tt_json = get_tiktok_json(video_url,browser_name)\n",
    "\n",
    "    if tt_json is not None:\n",
    "        video_id = list(tt_json['ItemModule'].keys())[0]\n",
    "\n",
    "        if save_video == True:\n",
    "            regex_url = re.findall(url_regex, video_url)[0]\n",
    "            if 'imagePost' in tt_json['ItemModule'][video_id]:\n",
    "                slidecount = 1\n",
    "                for slide in tt_json['ItemModule'][video_id]['imagePost']['images']:\n",
    "                    video_fn = regex_url.replace('/', '_') + '_slide_' + str(slidecount) + '.jpeg'\n",
    "                    tt_video_url = slide['imageURL']['urlList'][0]\n",
    "                    headers['referer'] = 'https://www.tiktok.com/'\n",
    "                    # include cookies with the video request\n",
    "                    if tt_video_url:\n",
    "                        try:\n",
    "                            tt_video = requests.get(tt_video_url, allow_redirects=True, headers=headers, cookies=cookies)\n",
    "                        except:\n",
    "                            print(\"timed out, moving on to next vid..\")\n",
    "                            locate_el = False\n",
    "                    if tt_video:\n",
    "                        with open(video_fn, 'wb') as fn:\n",
    "                            fn.write(tt_video.content)\n",
    "                    slidecount += 1\n",
    "            else:\n",
    "                regex_url = re.findall(url_regex, video_url)[0]\n",
    "                video_fn = regex_url.replace('/', '_') + '.mp4'\n",
    "                tt_video_url = tt_json['ItemModule'][video_id]['video']['downloadAddr']\n",
    "                headers['referer'] = 'https://www.tiktok.com/'\n",
    "                # include cookies with the video request\n",
    "                if tt_video_url:\n",
    "                    try:\n",
    "                        tt_video = requests.get(tt_video_url, allow_redirects=True, headers=headers, cookies=cookies)\n",
    "                    except:\n",
    "                            print(\"timed out, moving on to next vid..\")\n",
    "                            locate_el = False\n",
    "                if tt_video:\n",
    "                    with open(video_fn, 'wb') as fn:\n",
    "                        fn.write(tt_video.content)\n",
    "                print(\"Saved video\\n\", tt_video_url, \"\\nto\\n\", os.getcwd())\n",
    "        else:\n",
    "            print(\"not saving videos\")\n",
    "\n",
    "        if metadata_fn != '':\n",
    "            try:\n",
    "                data_slot = tt_json['ItemModule'][video_id]\n",
    "                data_row = generate_data_row(data_slot)\n",
    "            except:\n",
    "                locate_el = False\n",
    "            try:\n",
    "                user_id = list(tt_json['UserModule']['users'].keys())[0]\n",
    "                data_row.loc[0,\"author_verified\"] = tt_json['UserModule']['users'][user_id]['verified']\n",
    "            except Exception:\n",
    "                pass\n",
    "            try:\n",
    "                if os.path.exists(metadata_fn):\n",
    "                    metadata = pd.read_csv(metadata_fn,keep_default_na=False)\n",
    "                    combined_data = pd.concat([metadata,data_row])\n",
    "                else:\n",
    "                    combined_data = data_row\n",
    "                combined_data.to_csv(metadata_fn,index=False)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    else:\n",
    "        tt_json = alt_get_tiktok_json(video_url,browser_name)\n",
    "        regex_url = re.findall(url_regex, video_url)[0]\n",
    "        video_fn = regex_url.replace('/', '_') + '.mp4'\n",
    "        try:\n",
    "            tt_video_url = tt_json[\"__DEFAULT_SCOPE__\"]['webapp.video-detail']['itemInfo']['itemStruct']['video']['downloadAddr']\n",
    "        except:\n",
    "            locate_el = False\n",
    "        headers['referer'] = 'https://www.tiktok.com/'\n",
    "        # include cookies with the video request\n",
    "        if tt_video_url:\n",
    "            try:\n",
    "                tt_video = requests.get(tt_video_url, allow_redirects=True, headers=headers, cookies=cookies)\n",
    "            except:\n",
    "                print(\"timed out, moving on to next vid..\")\n",
    "                locate_el = False\n",
    "        if save_video == True and tt_video:\n",
    "            with open(video_fn, 'wb') as fn:\n",
    "                fn.write(tt_video.content)\n",
    "\n",
    "        if metadata_fn != '':\n",
    "            try:\n",
    "                data_slot = tt_json[\"__DEFAULT_SCOPE__\"]['webapp.video-detail']['itemInfo']['itemStruct']\n",
    "                data_row = generate_data_row(data_slot)\n",
    "            except:\n",
    "                locate_el = False\n",
    "            try:\n",
    "                user_id = list(tt_json['UserModule']['users'].keys())[0]\n",
    "                data_row.loc[0,\"author_verified\"] = tt_json[\"__DEFAULT_SCOPE__\"]['webapp.video-detail']['itemInfo']['itemStruct']['author']\n",
    "            except Exception:\n",
    "                pass\n",
    "            try:\n",
    "                if os.path.exists(metadata_fn):\n",
    "                    metadata = pd.read_csv(metadata_fn,keep_default_na=False)\n",
    "                    combined_data = pd.concat([metadata,data_row])\n",
    "                else:\n",
    "                    combined_data = data_row\n",
    "                combined_data.to_csv(metadata_fn,index=False)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    if not locate_el:\n",
    "        with open(\"failed_to_locate.csv\", 'a') as fn:\n",
    "                csvwriter = writer(fn)\n",
    "                csvwriter.writerow([video_url])\n",
    "                fn.close()\n",
    "\n",
    "    if save_video == True:\n",
    "        print(\"Saved video\\n\", tt_video_url, \"\\nto\\n\", os.getcwd())\n",
    "    if metadata_fn != '':\n",
    "        print(\"Saved metadata for video\\n\",video_url,\"\\nto\\n\",os.getcwd())\n",
    "\n",
    "def save_tiktok_multi_page(tiktok_url, #can be a user, hashtag, or music URL\n",
    "                           save_video=False,\n",
    "                           save_metadata=True,\n",
    "                           metadata_fn='',\n",
    "                           browser_name=None):\n",
    "    if 'cookies' not in globals() and browser_name is None:\n",
    "        raise BrowserNotSpecifiedError\n",
    "    tt_json = get_tiktok_json(tiktok_url,browser_name)\n",
    "    data_loc = tt_json['ItemModule']\n",
    "    regex_url = re.findall(url_regex,tiktok_url)[0]\n",
    "    if save_metadata == True and metadata_fn == '':\n",
    "        metadata_fn = regex_url.replace('/','_') + '.csv'\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    for v in data_loc:\n",
    "        data = pd.concat([data,generate_data_row(data_loc[v])])\n",
    "        if save_video == True:\n",
    "            video_url = 'https://www.tiktok.com/@' + data_loc[v]['author'] + '/video/' + data_loc[v]['id']\n",
    "            save_tiktok(video_url,True)\n",
    "    if save_metadata == True:\n",
    "        data = deduplicate_metadata(metadata_fn,data)\n",
    "        data.to_csv(metadata_fn,index=False)\n",
    "    print('Saved',len(data_loc),'videos and/or lines of metadata')\n",
    "\n",
    "def save_tiktok_multi_urls(video_urls,\n",
    "                           save_video=True,\n",
    "                           metadata_fn='',\n",
    "                           sleep=4,\n",
    "                           browser_name=None):\n",
    "    if 'cookies' not in globals() and browser_name is None:\n",
    "        raise BrowserNotSpecifiedError\n",
    "    if type(video_urls) is str:\n",
    "        tt_urls = open(video_urls).read().splitlines()\n",
    "    else:\n",
    "        tt_urls = video_urls\n",
    "\n",
    "    with open(\"failed_to_locate.csv\", 'w') as fn:\n",
    "                csvwriter = writer(fn)\n",
    "                csvwriter.writerow([\"video_url\"])\n",
    "                fn.close()\n",
    "\n",
    "    for u in tt_urls:\n",
    "        save_tiktok(u,save_video,metadata_fn,browser_name)\n",
    "        time.sleep(random.randint(1, sleep))\n",
    "    print('Saved',len(tt_urls),'videos and/or lines of metadata')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fedc64df-ae99-4608-92ab-732c5903733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_row_new(video_obj, search_term, year):\n",
    "    data_header = ['video_id',\n",
    "                   'video_timestamp',\n",
    "                   'video_duration',\n",
    "                   'video_locationcreated',\n",
    "                   'suggested_words',\n",
    "                   'video_diggcount',\n",
    "                   'video_sharecount',\n",
    "                   'video_commentcount',\n",
    "                   'video_playcount',\n",
    "                   'video_description',\n",
    "                   'video_is_ad',\n",
    "                   'video_stickers',\n",
    "                   'author_username',\n",
    "                   'author_name',\n",
    "                   'author_followercount',\n",
    "                   'author_followingcount',\n",
    "                   'author_heartcount',\n",
    "                   'author_videocount',\n",
    "                   'author_diggcount',\n",
    "                   'author_verified',\n",
    "                   #added col headers here\n",
    "                  'search_term',\n",
    "                  'year']\n",
    "    data_list = []\n",
    "    data_list.append(video_obj['id'])\n",
    "    try:\n",
    "        ctime = video_obj['createTime']\n",
    "        data_list.append(datetime.fromtimestamp(int(ctime)).isoformat())\n",
    "    except Exception:\n",
    "        data_list.append('')\n",
    "    try:\n",
    "        data_list.append(video_obj['video']['duration'])\n",
    "    except Exception:\n",
    "        data_list.append(np.nan)\n",
    "    try:\n",
    "        data_list.append(video_obj['locationCreated'])\n",
    "    except Exception:\n",
    "        data_list.append('')\n",
    "    try:\n",
    "        data_list.append(\", \".join(video_obj['suggestedWords']))\n",
    "    except Exception:\n",
    "        data_list.append('')\n",
    "    try:\n",
    "        data_list.append(video_obj['stats']['diggCount'])\n",
    "    except Exception:\n",
    "        data_list.append(np.nan)\n",
    "    try:\n",
    "        data_list.append(video_obj['stats']['shareCount'])\n",
    "    except Exception:\n",
    "        data_list.append(np.nan)\n",
    "    try:\n",
    "        data_list.append(video_obj['stats']['commentCount'])\n",
    "    except Exception:\n",
    "        data_list.append(np.nan)\n",
    "    try:\n",
    "        data_list.append(video_obj['stats']['playCount'])\n",
    "    except Exception:\n",
    "        data_list.append(np.nan)\n",
    "    try:\n",
    "        data_list.append(video_obj['desc'])\n",
    "    except Exception:\n",
    "        data_list.append('')\n",
    "    try:\n",
    "        data_list.append(video_obj['isAd'])\n",
    "    except Exception:\n",
    "        data_list.append(False)\n",
    "    try:\n",
    "        video_stickers = []\n",
    "        for sticker in video_obj['stickersOnItem']:\n",
    "            for text in sticker['stickerText']:\n",
    "                video_stickers.append(text)\n",
    "        data_list.append(';'.join(video_stickers))\n",
    "    except Exception:\n",
    "        data_list.append('')\n",
    "    try:\n",
    "        data_list.append(video_obj['author']['uniqueId'])\n",
    "    except Exception:\n",
    "        try:\n",
    "            data_list.append(video_obj['author'])\n",
    "        except Exception:\n",
    "            data_list.append('')\n",
    "    try:\n",
    "        data_list.append(video_obj['author']['nickname'])\n",
    "    except Exception:\n",
    "        try:\n",
    "            data_list.append(video_obj['nickname'])\n",
    "        except Exception:\n",
    "            data_list.append('')\n",
    "    try:\n",
    "        data_list.append(video_obj['authorStats']['followerCount'])\n",
    "    except Exception:\n",
    "        data_list.append(np.nan)\n",
    "    try:\n",
    "        data_list.append(video_obj['authorStats']['followingCount'])\n",
    "    except Exception:\n",
    "        data_list.append(np.nan)\n",
    "    try:\n",
    "        data_list.append(video_obj['authorStats']['heartCount'])\n",
    "    except Exception:\n",
    "        data_list.append(np.nan)\n",
    "    try:\n",
    "        data_list.append(video_obj['authorStats']['videoCount'])\n",
    "    except Exception:\n",
    "        data_list.append(np.nan)\n",
    "    try:\n",
    "        data_list.append(video_obj['authorStats']['diggCount'])\n",
    "    except Exception:\n",
    "        data_list.append(np.nan)\n",
    "    try:\n",
    "        data_list.append(video_obj['author']['verified'])\n",
    "    except Exception:\n",
    "        data_list.append(False)\n",
    "    #appending search term and year info\n",
    "    try:\n",
    "        data_list.append(search_term)\n",
    "    except Exception:\n",
    "        data_list.append('')\n",
    "    try:\n",
    "        data_list.append(year)\n",
    "    except Exception:\n",
    "        data_list.append('')\n",
    "    data_row = pd.DataFrame(dict(zip(data_header,data_list)),index=[0])\n",
    "    return data_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d8f6c6d-043a-4b02-83b7-05d44ec177de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tiktok_multi_urls_new(video_urls,\n",
    "                               #adding new params\n",
    "                              search_term, \n",
    "                              year,\n",
    "                           save_video=True,\n",
    "                           metadata_fn='',\n",
    "                           sleep=4,\n",
    "                           browser_name=None, ):\n",
    "    if 'cookies' not in globals() and browser_name is None:\n",
    "        raise BrowserNotSpecifiedError\n",
    "    if type(video_urls) is str:\n",
    "        tt_urls = open(video_urls).read().splitlines()\n",
    "    else:\n",
    "        tt_urls = video_urls\n",
    "\n",
    "    with open(\"failed_to_locate.csv\", 'w') as fn:\n",
    "                csvwriter = writer(fn)\n",
    "                csvwriter.writerow([\"video_url\"])\n",
    "                fn.close()\n",
    "\n",
    "    for u in tt_urls:\n",
    "        save_tiktok_new(u,save_video,metadata_fn,browser_name, search_term, year)\n",
    "        time.sleep(random.randint(1, sleep))\n",
    "    print('Saved',len(tt_urls),'videos and/or lines of metadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d4e1999-2086-4743-8174-f1c3b8001a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tiktok_new(video_url,\n",
    "                    #adding new params\n",
    "                    search_term, year,\n",
    "                save_video=True,\n",
    "                metadata_fn='',\n",
    "                browser_name=None):\n",
    "    if 'cookies' not in globals() and browser_name is None:\n",
    "        raise BrowserNotSpecifiedError\n",
    "    if save_video == False and metadata_fn == '':\n",
    "        print('Since save_video and metadata_fn are both False/blank, the program did nothing.')\n",
    "        return\n",
    "    \n",
    "    tt_video = None\n",
    "    tt_video_url = None\n",
    "    data_row = None\n",
    "    locate_el = True\n",
    "    tt_json = get_tiktok_json(video_url,browser_name)\n",
    "\n",
    "    if tt_json is not None:\n",
    "        video_id = list(tt_json['ItemModule'].keys())[0]\n",
    "\n",
    "        if save_video == True:\n",
    "            regex_url = re.findall(url_regex, video_url)[0]\n",
    "            if 'imagePost' in tt_json['ItemModule'][video_id]:\n",
    "                slidecount = 1\n",
    "                for slide in tt_json['ItemModule'][video_id]['imagePost']['images']:\n",
    "                    video_fn = regex_url.replace('/', '_') + '_slide_' + str(slidecount) + '.jpeg'\n",
    "                    tt_video_url = slide['imageURL']['urlList'][0]\n",
    "                    headers['referer'] = 'https://www.tiktok.com/'\n",
    "                    # include cookies with the video request\n",
    "                    if tt_video_url:\n",
    "                        try:\n",
    "                            tt_video = requests.get(tt_video_url, allow_redirects=True, headers=headers, cookies=cookies)\n",
    "                        except:\n",
    "                            print(\"timed out, moving on to next vid..\")\n",
    "                            locate_el = False\n",
    "                    if tt_video:\n",
    "                        with open(video_fn, 'wb') as fn:\n",
    "                            fn.write(tt_video.content)\n",
    "                    slidecount += 1\n",
    "            else:\n",
    "                regex_url = re.findall(url_regex, video_url)[0]\n",
    "                video_fn = regex_url.replace('/', '_') + '.mp4'\n",
    "                tt_video_url = tt_json['ItemModule'][video_id]['video']['downloadAddr']\n",
    "                headers['referer'] = 'https://www.tiktok.com/'\n",
    "                # include cookies with the video request\n",
    "                if tt_video_url:\n",
    "                    try:\n",
    "                        tt_video = requests.get(tt_video_url, allow_redirects=True, headers=headers, cookies=cookies)\n",
    "                    except:\n",
    "                            print(\"timed out, moving on to next vid..\")\n",
    "                            locate_el = False\n",
    "                if tt_video:\n",
    "                    with open(video_fn, 'wb') as fn:\n",
    "                        fn.write(tt_video.content)\n",
    "                print(\"Saved video\\n\", tt_video_url, \"\\nto\\n\", os.getcwd())\n",
    "        else:\n",
    "            print(\"not saving videos\")\n",
    "\n",
    "        if metadata_fn != '':\n",
    "            try:\n",
    "                data_slot = tt_json['ItemModule'][video_id]\n",
    "                data_row = generate_data_row_new(data_slot, search_term, year)\n",
    "            except:\n",
    "                locate_el = False\n",
    "            try:\n",
    "                user_id = list(tt_json['UserModule']['users'].keys())[0]\n",
    "                data_row.loc[0,\"author_verified\"] = tt_json['UserModule']['users'][user_id]['verified']\n",
    "            except Exception:\n",
    "                pass\n",
    "            try:\n",
    "                if os.path.exists(metadata_fn):\n",
    "                    metadata = pd.read_csv(metadata_fn,keep_default_na=False)\n",
    "                    combined_data = pd.concat([metadata,data_row])\n",
    "                else:\n",
    "                    combined_data = data_row\n",
    "                combined_data.to_csv(metadata_fn,index=False)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    else:\n",
    "        tt_json = alt_get_tiktok_json(video_url,browser_name)\n",
    "        regex_url = re.findall(url_regex, video_url)[0]\n",
    "        video_fn = regex_url.replace('/', '_') + '.mp4'\n",
    "        try:\n",
    "            tt_video_url = tt_json[\"__DEFAULT_SCOPE__\"]['webapp.video-detail']['itemInfo']['itemStruct']['video']['downloadAddr']\n",
    "        except:\n",
    "            locate_el = False\n",
    "        headers['referer'] = 'https://www.tiktok.com/'\n",
    "        # include cookies with the video request\n",
    "        if tt_video_url:\n",
    "            try:\n",
    "                tt_video = requests.get(tt_video_url, allow_redirects=True, headers=headers, cookies=cookies)\n",
    "            except:\n",
    "                print(\"timed out, moving on to next vid..\")\n",
    "                locate_el = False\n",
    "        if save_video == True and tt_video:\n",
    "            with open(video_fn, 'wb') as fn:\n",
    "                fn.write(tt_video.content)\n",
    "\n",
    "        if metadata_fn != '':\n",
    "            try:\n",
    "                data_slot = tt_json[\"__DEFAULT_SCOPE__\"]['webapp.video-detail']['itemInfo']['itemStruct']\n",
    "                data_row = generate_data_row_new(data_slot, search_term, year)\n",
    "            except:\n",
    "                locate_el = False\n",
    "            try:\n",
    "                user_id = list(tt_json['UserModule']['users'].keys())[0]\n",
    "                data_row.loc[0,\"author_verified\"] = tt_json[\"__DEFAULT_SCOPE__\"]['webapp.video-detail']['itemInfo']['itemStruct']['author']\n",
    "            except Exception:\n",
    "                pass\n",
    "            try:\n",
    "                if os.path.exists(metadata_fn):\n",
    "                    metadata = pd.read_csv(metadata_fn,keep_default_na=False)\n",
    "                    combined_data = pd.concat([metadata,data_row])\n",
    "                else:\n",
    "                    combined_data = data_row\n",
    "                combined_data.to_csv(metadata_fn,index=False)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    if not locate_el:\n",
    "        with open(\"failed_to_locate.csv\", 'a') as fn:\n",
    "                csvwriter = writer(fn)\n",
    "                csvwriter.writerow([video_url])\n",
    "                fn.close()\n",
    "\n",
    "    if save_video == True:\n",
    "        print(\"Saved video\\n\", tt_video_url, \"\\nto\\n\", os.getcwd())\n",
    "    if metadata_fn != '':\n",
    "        print(\"Saved metadata for video\\n\",video_url,\"\\nto\\n\",os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b4dc58-7c94-4df4-ae25-ccde76e4d8f1",
   "metadata": {},
   "source": [
    "## Modifying Pyktok Collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4228186d-6452-4c55-a750-fa80a2b53e03",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected unindent (1143476850.py, line 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[15], line 35\u001b[0;36m\u001b[0m\n\u001b[0;31m    if __name__ == \"__main__\":\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected unindent\n"
     ]
    }
   ],
   "source": [
    "def collect_metadata(inputFile, outputFile):\n",
    "    \"\"\"Call pyktok with a list of URLs to collect post metadata.\n",
    "    \"\"\"\n",
    "    pyk.specify_browser('chrome')\n",
    "    try:\n",
    "        with open(inputFile) as fin:\n",
    "            data = json.load(fin)\n",
    "            #storing year data\n",
    "            first_key = list(data.keys())[0]\n",
    "            year = data[first_key]['year']\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{inputFile}' couldn't be found.\")\n",
    "        return \n",
    "    \n",
    "    try:\n",
    "        for key in data:\n",
    "            search_term = key\n",
    "            urls = data[key]['urls']\n",
    "\n",
    "            pyk.save_tiktok_multi_urls_new(urls,  # list of URLs to visit\n",
    "                                           search_term, year,\n",
    "                               False, # don't save videos   \n",
    "                \t\t       outputFile, # csv file\n",
    "                \t\t       5) # max time sleep\n",
    "      #urls = []\n",
    "      #  [urls.append(url) for search_term in data for url in data[search_term]['urls']]\n",
    "        #urls = [entry[search_term]['urls'] for entry in data for search_term in entry]\n",
    "   # except:\n",
    "   #     print(\"There is something wrong with the data format.\")\n",
    "   #     return\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    _, fin, fout = sys.argv\n",
    "    collect_metadata(fin, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da30cb8-a738-4267-901f-72b6a9c2451e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
