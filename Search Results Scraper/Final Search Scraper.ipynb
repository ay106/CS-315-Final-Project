{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8b3064e-9fd7-4aa2-9013-77a2d8e89c6f",
   "metadata": {},
   "source": [
    "## Final Search Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146b8883-eea9-4f7c-9e03-65e16025a6e7",
   "metadata": {},
   "source": [
    "Author: Miraya Gupta\\\n",
    "Date: 17/04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9ad55ad-4230-4ab6-a369-e866b6947c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import selenium\n",
    "from seleniumbase import Driver\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By # contains operators for the type of search we want to do\n",
    "import time\n",
    "from seleniumbase import BaseCase\n",
    "from random import randint\n",
    "#from selenium.common.exceptions import ElementClickInterceptedException, StaleElementReferenceException, NoSuchElementException\n",
    "import html\n",
    "#import re\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import json\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ae3731-a0f8-4e6d-807f-66ad81e192e6",
   "metadata": {},
   "source": [
    "## 1. Dividing Search Terms into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e20680a-a53f-41d0-89b5-b929ec0f0131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: dict_keys(['2020', '2021', '2022', '2023', '2024'])\n",
      "Articles from 2020: 60\n",
      "Articles from 2021: 60\n",
      "Articles from 2022: 60\n",
      "Articles from 2023: 60\n",
      "Articles from 2024: 62\n",
      "New articles from 2024: 60\n"
     ]
    }
   ],
   "source": [
    "#locate json file\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "file_path = os.path.join(parent_dir, 'NYT_Data/suggested_words.json')\n",
    "\n",
    "#open json of search terms \n",
    "with open (file_path, 'r') as f:\n",
    "    search_terms_by_year = json.load(f)\n",
    "\n",
    "#Checking search terms\n",
    "print(f'Keys: {search_terms_by_year.keys()}')\n",
    "print(f'Articles from 2020: {len(search_terms_by_year[\"2020\"])}')\n",
    "print(f'Articles from 2021: {len(search_terms_by_year[\"2021\"])}')\n",
    "print(f'Articles from 2022: {len(search_terms_by_year[\"2022\"])}')\n",
    "print(f'Articles from 2023: {len(search_terms_by_year[\"2023\"])}')\n",
    "print(f'Articles from 2024: {len(search_terms_by_year[\"2024\"])}')\n",
    "\n",
    "#correcting errors\n",
    "search_terms_by_year['2024'] = search_terms_by_year['2024'][:60]\n",
    "print(f'New articles from 2024: {len(search_terms_by_year[\"2024\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e885f0e8-cfc2-4e1c-b535-8badb9de0489",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating lists for each year\n",
    "search_terms_2020 = search_terms_by_year[\"2020\"]\n",
    "search_terms_2021 = search_terms_by_year[\"2021\"]\n",
    "search_terms_2022 = search_terms_by_year[\"2022\"]\n",
    "search_terms_2023 = search_terms_by_year[\"2023\"]\n",
    "search_terms_2024 = search_terms_by_year[\"2024\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcd66f9-f937-4679-8f46-6abd3bc00df4",
   "metadata": {},
   "source": [
    "## 2. Scraping TikTok Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d694ab7-0576-4611-b2a3-d58e9601c2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_50_urls(search_term, no_of_results=10):\n",
    "    #open link using driver\n",
    "    driver.get(f'https://www.tiktok.com/search/video?q={search_term}&t={no_of_results}')\n",
    "    #time.sleep(20)\n",
    "    #perform scrolling and collect urls\n",
    "    all_urls = []\n",
    "    try:\n",
    "        for i in range(6):\n",
    "            for i in range(30):\n",
    "                actions.send_keys(Keys.ARROW_DOWN)\n",
    "            actions.perform()\n",
    "            time.sleep(0.75)\n",
    "            videos = driver.find_elements(By.XPATH, \"//div[contains(@class, 'css-1soki6-DivItemContainerForSearch e19c29qe10')]\")\n",
    "            [all_urls.append(video.find_element (By. TAG_NAME, \"a\").get_attribute('href')) for video in videos if video not in all_urls]\n",
    "    except:\n",
    "        print(f'Error, {search_term}')\n",
    "        print('All URLs:')\n",
    "        print(all_urls)\n",
    "    #return search term and list of urls as a tuple\n",
    "    try:\n",
    "        return search_term, all_urls[:50]\n",
    "    except:\n",
    "        print(f'Error, {search_term}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94f775b3-4999-4231-a754-1357d3e868be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to take a list of keywords and run TikTok search on all of them. Outputs a json file of the search terms as \n",
    "# keys and the list of 50 urls as values. \n",
    "def run_all_search_terms(search_terms_list, year):\n",
    "    result_dict = {}\n",
    "    for search_term in search_terms_list:\n",
    "        search_term_dct = {}\n",
    "        data = get_50_urls(search_term, no_of_results=10)\n",
    "        keyword = data[0]\n",
    "        urls = data[1]\n",
    "        search_term_dct['urls'] = urls\n",
    "        search_term_dct['year'] = year\n",
    "        result_dict[search_term] = search_term_dct\n",
    "    with open(f'urls{year}.json', 'w') as f:\n",
    "        json.dump(result_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fa5797-f002-4055-9114-102267d834e5",
   "metadata": {},
   "source": [
    "## 3. Calling Functions for Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a6097a6c-630e-4bc5-84a7-eba848c61530",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start with driver instance so we don't have to login multiple times. \n",
    "driver = webdriver.Chrome()\n",
    "driver.get(f'https://www.tiktok.com')\n",
    "actions = ActionChains(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c24ed5cf-916d-4d2d-be5e-f984b338d96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 377.0831289291382 seconds\n"
     ]
    }
   ],
   "source": [
    "#change parameters every time, 2020, 2021, 2022, 2023, 2024. Rerun the above cell every time this cell is run \n",
    "# to login to a new account. \n",
    "start_time = time.time()\n",
    "run_all_search_terms(search_terms_2024, '2024')\n",
    "end_time = time.time()\n",
    "print(\"Execution time:\", end_time-start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b44e5be-dfa7-4ab8-b361-f44e0a74b41d",
   "metadata": {},
   "source": [
    "## 4. Analysing Missing Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "42c12fb6-389d-4631-91f4-6f6f4837d8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_no_results = {}\n",
    "try:\n",
    "    for file in ['urls2020.json','urls2021.json', 'urls2022.json', 'urls2023.json', 'urls2024.json']:\n",
    "        year_dct = {}\n",
    "        with open (file, 'r') as inF:\n",
    "            i = 0\n",
    "            no_result_count = 0\n",
    "            no_result_terms = []\n",
    "            dct = json.load(inF)\n",
    "            for search_term in dct.keys():\n",
    "                if len(dct[search_term]['urls']) == 0:\n",
    "                    no_result_count += 1\n",
    "                    no_result_terms.append(search_term)\n",
    "                if i == 0:\n",
    "                    year = dct[search_term]['year']\n",
    "                    i += 1\n",
    "                year_dct['no_result_terms'] = no_result_terms\n",
    "                year_dct['no_result_count'] = no_result_count\n",
    "        all_no_results[year] = year_dct\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print('File not found')\n",
    "    \n",
    "    with open ('no_search_results.json', 'w') as outF:\n",
    "        json.dump(all_no_results, outF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae9dfea-4e20-4fe5-ba3e-098878210e64",
   "metadata": {},
   "source": [
    "## Dividing into Chunks for Pyktok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4ccb0d-558c-424f-9f44-c615dc6533a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
